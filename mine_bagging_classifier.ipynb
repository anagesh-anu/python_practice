{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9587af3e-c794-4c6c-916f-c09635344880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d22c4c5-b6af-4153-bcd5-f00715ffb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc6e10d0-7247-42d6-9787-37c72ad58e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data set in a dataframe\n",
    "digit = load_digits(return_X_y = True, as_frame= True)\n",
    "digit[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd720d9d-0d1e-4b35-8611-53ab705d3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7be6769-bcf2-44ea-9819-4ffa2a6ed632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load data set in the form of ndarray\n",
    "digit = load_digits()\n",
    "X, y = digit.data, digit.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a10dd1a-92e7-462d-8448-5987c1afef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAGkCAYAAAAIduO+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYkElEQVR4nO3df2yUhR3H8c9B4VBsz4IU23BARSI/CogtcwWcP8AmDRLJNtQFWR1zWWdBsDHR6h+yXxz+sUUXZrMy0kkIlpAJsmyAJZPiYrqVaiNDg7ASeyisgcFd6ZIjts/+8mKH/fEc/fL0ub5fyZN5t+e8T0zl7dO79gKO4zgCAMDICK8HAADSG6EBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYSpvQvPbaa8rPz9eYMWNUWFiod9991+tJ/Tpy5IiWL1+uvLw8BQIB7d271+tJAxKJRLRgwQJlZmYqJydHK1as0IkTJ7yeNSDV1dWaO3eusrKylJWVpeLiYu3fv9/rWa5FIhEFAgFt2LDB6yn92rhxowKBQI/j1ltv9XrWgHz22Wd6/PHHNX78eN14442688471dzc7PWsfk2dOvWqf+aBQEAVFRWe7EmL0OzatUsbNmzQiy++qA8++ED33HOPSktL1dbW5vW0PnV2dmrevHnasmWL11NcaWhoUEVFhRobG1VfX68vvvhCJSUl6uzs9HpavyZNmqTNmzfr6NGjOnr0qB544AE9/PDDOn78uNfTBqypqUk1NTWaO3eu11MGbPbs2Tp79mzyOHbsmNeT+nXx4kUtWrRIo0aN0v79+/XRRx/pV7/6lW6++Wavp/Wrqampxz/v+vp6SdLKlSu9GeSkgW984xtOeXl5j/tmzJjhPP/88x4tck+Ss2fPHq9npKS9vd2R5DQ0NHg9JSXZ2dnO73//e69nDEhHR4czffp0p76+3rn33nud9evXez2pXy+99JIzb948r2e49txzzzmLFy/2esagWL9+vTNt2jSnu7vbk+f3/RXNlStX1NzcrJKSkh73l5SU6L333vNo1fASi8UkSePGjfN4iTtdXV2qq6tTZ2eniouLvZ4zIBUVFVq2bJmWLl3q9RRXTp48qby8POXn5+uxxx5Ta2ur15P6tW/fPhUVFWnlypXKycnR/PnztXXrVq9nuXblyhXt2LFDa9asUSAQ8GSD70Nz/vx5dXV1aeLEiT3unzhxos6dO+fRquHDcRxVVlZq8eLFKigo8HrOgBw7dkw33XSTgsGgysvLtWfPHs2aNcvrWf2qq6vT+++/r0gk4vUUV+6++25t375dBw8e1NatW3Xu3DktXLhQFy5c8Hpan1pbW1VdXa3p06fr4MGDKi8v19NPP63t27d7Pc2VvXv36tKlS3riiSc825Dh2TMPsv8vteM4ntV7OFm7dq0+/PBD/e1vf/N6yoDdcccdamlp0aVLl/THP/5RZWVlamhoGNKxiUajWr9+vd5++22NGTPG6zmulJaWJv96zpw5Ki4u1rRp0/T666+rsrLSw2V96+7uVlFRkTZt2iRJmj9/vo4fP67q6mp9//vf93jdwG3btk2lpaXKy8vzbIPvr2huueUWjRw58qqrl/b29quucjC41q1bp3379umdd97RpEmTvJ4zYKNHj9btt9+uoqIiRSIRzZs3T6+++qrXs/rU3Nys9vZ2FRYWKiMjQxkZGWpoaNBvfvMbZWRkqKury+uJAzZ27FjNmTNHJ0+e9HpKn3Jzc6/6j4+ZM2cO+TcZfdWnn36qQ4cO6cknn/R0h+9DM3r0aBUWFibfVfGl+vp6LVy40KNV6c1xHK1du1Zvvvmm/vrXvyo/P9/rSdfEcRwlEgmvZ/RpyZIlOnbsmFpaWpJHUVGRVq1apZaWFo0cOdLriQOWSCT08ccfKzc31+spfVq0aNFVb9v/5JNPNGXKFI8WuVdbW6ucnBwtW7bM0x1p8a2zyspKrV69WkVFRSouLlZNTY3a2tpUXl7u9bQ+Xb58WadOnUrePn36tFpaWjRu3DhNnjzZw2V9q6io0M6dO/XWW28pMzMzeTUZCoV0ww03eLyuby+88IJKS0sVDofV0dGhuro6HT58WAcOHPB6Wp8yMzOveg1s7NixGj9+/JB/bezZZ5/V8uXLNXnyZLW3t+sXv/iF4vG4ysrKvJ7Wp2eeeUYLFy7Upk2b9Mgjj+gf//iHampqVFNT4/W0Aenu7lZtba3KysqUkeHxH/WevNfNwG9/+1tnypQpzujRo5277rrLF2+1feeddxxJVx1lZWVeT+vT122W5NTW1no9rV9r1qxJfp1MmDDBWbJkifP22297PSslfnl786OPPurk5uY6o0aNcvLy8pxvf/vbzvHjx72eNSB/+tOfnIKCAicYDDozZsxwampqvJ40YAcPHnQkOSdOnPB6ihNwHMfxJnEAgOHA96/RAACGNkIDADBFaAAApggNAMAUoQEAmCI0AABTaRWaRCKhjRs3Dvmf8v5/ft0t+Xe7X3dL/t3u192Sf7cPld1p9XM08XhcoVBIsVhMWVlZXs8ZML/ulvy73a+7Jf9u9+tuyb/bh8rutLqiAQAMPYQGAGDquv+mte7ubn3++efKzMwc9M+LicfjPf7XL/y6W/Lvdr/ulvy73a+7Jf9ut97tOI46OjqUl5enESN6v2657q/RnDlzRuFw+Ho+JQDAUDQa7fMzqa77FU1mZub1fkpIWrFihdcTUrJx40avJ6Ts8OHDXk9IiZ//mV+6dMnrCcNSf3+uX/fQ8PHK3hg1apTXE1Li5/8wGeqfzdMb/h2FW/19zfBmAACAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATKUUmtdee035+fkaM2aMCgsL9e677w72LgBAmnAdml27dmnDhg168cUX9cEHH+iee+5RaWmp2traLPYBAHzOdWh+/etf64c//KGefPJJzZw5U6+88orC4bCqq6st9gEAfM5VaK5cuaLm5maVlJT0uL+kpETvvffe1z4mkUgoHo/3OAAAw4er0Jw/f15dXV2aOHFij/snTpyoc+fOfe1jIpGIQqFQ8giHw6mvBQD4TkpvBggEAj1uO45z1X1fqqqqUiwWSx7RaDSVpwQA+FSGm5NvueUWjRw58qqrl/b29quucr4UDAYVDAZTXwgA8DVXVzSjR49WYWGh6uvre9xfX1+vhQsXDuowAEB6cHVFI0mVlZVavXq1ioqKVFxcrJqaGrW1tam8vNxiHwDA51yH5tFHH9WFCxf0s5/9TGfPnlVBQYH+8pe/aMqUKRb7AAA+5zo0kvTUU0/pqaeeGuwtAIA0xO86AwCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAVEoffAb/2bx5s9cTUnLbbbd5PSFl2dnZXk9IyX/+8x+vJ6TskUce8XpCSnbv3u31BFNc0QAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAw5To0R44c0fLly5WXl6dAIKC9e/cazAIApAvXoens7NS8efO0ZcsWiz0AgDST4fYBpaWlKi0ttdgCAEhDrkPjViKRUCKRSN6Ox+PWTwkAGELM3wwQiUQUCoWSRzgctn5KAMAQYh6aqqoqxWKx5BGNRq2fEgAwhJh/6ywYDCoYDFo/DQBgiOLnaAAAplxf0Vy+fFmnTp1K3j59+rRaWlo0btw4TZ48eVDHAQD8z3Vojh49qvvvvz95u7KyUpJUVlamP/zhD4M2DACQHlyH5r777pPjOBZbAABpiNdoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAw5fqDz4azwsJCryek7LbbbvN6QkqmTZvm9YSUtba2ej0hJfX19V5PSJlf/x3dvXu31xNMcUUDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmXIUmEolowYIFyszMVE5OjlasWKETJ05YbQMApAFXoWloaFBFRYUaGxtVX1+vL774QiUlJers7LTaBwDwuQw3Jx84cKDH7draWuXk5Ki5uVnf+ta3BnUYACA9uArN/4vFYpKkcePG9XpOIpFQIpFI3o7H49fylAAAn0n5zQCO46iyslKLFy9WQUFBr+dFIhGFQqHkEQ6HU31KAIAPpRyatWvX6sMPP9Qbb7zR53lVVVWKxWLJIxqNpvqUAAAfSulbZ+vWrdO+fft05MgRTZo0qc9zg8GggsFgSuMAAP7nKjSO42jdunXas2ePDh8+rPz8fKtdAIA04So0FRUV2rlzp9566y1lZmbq3LlzkqRQKKQbbrjBZCAAwN9cvUZTXV2tWCym++67T7m5uclj165dVvsAAD7n+ltnAAC4we86AwCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAlKsPPhvusrOzvZ6QsubmZq8npKS1tdXrCcOOX79WMHRxRQMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAlKvQVFdXa+7cucrKylJWVpaKi4u1f/9+q20AgDTgKjSTJk3S5s2bdfToUR09elQPPPCAHn74YR0/ftxqHwDA5zLcnLx8+fIet3/5y1+qurpajY2Nmj179qAOAwCkB1eh+aquri7t3r1bnZ2dKi4u7vW8RCKhRCKRvB2Px1N9SgCAD7l+M8CxY8d00003KRgMqry8XHv27NGsWbN6PT8SiSgUCiWPcDh8TYMBAP7iOjR33HGHWlpa1NjYqJ/85CcqKyvTRx991Ov5VVVVisViySMajV7TYACAv7j+1tno0aN1++23S5KKiorU1NSkV199Vb/73e++9vxgMKhgMHhtKwEAvnXNP0fjOE6P12AAAPgqV1c0L7zwgkpLSxUOh9XR0aG6ujodPnxYBw4csNoHAPA5V6H597//rdWrV+vs2bMKhUKaO3euDhw4oAcffNBqHwDA51yFZtu2bVY7AABpit91BgAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKVcffDbcZWdnez0hZYcOHfJ6AnzCz1/nFy9e9HoCvgZXNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYOqaQhOJRBQIBLRhw4ZBmgMASDcph6apqUk1NTWaO3fuYO4BAKSZlEJz+fJlrVq1Slu3blV2dvZgbwIApJGUQlNRUaFly5Zp6dKl/Z6bSCQUj8d7HACA4SPD7QPq6ur0/vvvq6mpaUDnRyIR/fSnP3U9DACQHlxd0USjUa1fv147duzQmDFjBvSYqqoqxWKx5BGNRlMaCgDwJ1dXNM3NzWpvb1dhYWHyvq6uLh05ckRbtmxRIpHQyJEjezwmGAwqGAwOzloAgO+4Cs2SJUt07NixHvf94Ac/0IwZM/Tcc89dFRkAAFyFJjMzUwUFBT3uGzt2rMaPH3/V/QAASPxmAACAMdfvOvt/hw8fHoQZAIB0xRUNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmrvmDz4aTixcvej0hZYWFhV5PGHays7O9npASP3+t7N692+sJ+Bpc0QAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAw5So0GzduVCAQ6HHceuutVtsAAGkgw+0DZs+erUOHDiVvjxw5clAHAQDSi+vQZGRkcBUDABgw16/RnDx5Unl5ecrPz9djjz2m1tbWPs9PJBKKx+M9DgDA8OEqNHfffbe2b9+ugwcPauvWrTp37pwWLlyoCxcu9PqYSCSiUCiUPMLh8DWPBgD4h6vQlJaW6jvf+Y7mzJmjpUuX6s9//rMk6fXXX+/1MVVVVYrFYskjGo1e22IAgK+4fo3mq8aOHas5c+bo5MmTvZ4TDAYVDAav5WkAAD52TT9Hk0gk9PHHHys3N3ew9gAA0oyr0Dz77LNqaGjQ6dOn9fe//13f/e53FY/HVVZWZrUPAOBzrr51dubMGX3ve9/T+fPnNWHCBH3zm99UY2OjpkyZYrUPAOBzrkJTV1dntQMAkKb4XWcAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJhy9cFnw11ra6vXE1JWWFjo9YSUrFy50usJKfPzdr96+eWXvZ6Ar8EVDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmHIdms8++0yPP/64xo8frxtvvFF33nmnmpubLbYBANJAhpuTL168qEWLFun+++/X/v37lZOTo3/961+6+eabjeYBAPzOVWhefvllhcNh1dbWJu+bOnXqYG8CAKQRV98627dvn4qKirRy5Url5ORo/vz52rp1a5+PSSQSisfjPQ4AwPDhKjStra2qrq7W9OnTdfDgQZWXl+vpp5/W9u3be31MJBJRKBRKHuFw+JpHAwD8w1Vouru7ddddd2nTpk2aP3++fvzjH+tHP/qRqqure31MVVWVYrFY8ohGo9c8GgDgH65Ck5ubq1mzZvW4b+bMmWpra+v1McFgUFlZWT0OAMDw4So0ixYt0okTJ3rc98knn2jKlCmDOgoAkD5cheaZZ55RY2OjNm3apFOnTmnnzp2qqalRRUWF1T4AgM+5Cs2CBQu0Z88evfHGGyooKNDPf/5zvfLKK1q1apXVPgCAz7n6ORpJeuihh/TQQw9ZbAEApCF+1xkAwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKZcf/DZcNba2ur1hJQ9//zzXk9IyebNm72ekLLm5mavJ6SkqKjI6wlIM1zRAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADDlKjRTp05VIBC46qioqLDaBwDwuQw3Jzc1Namrqyt5+5///KcefPBBrVy5ctCHAQDSg6vQTJgwocftzZs3a9q0abr33nsHdRQAIH24Cs1XXblyRTt27FBlZaUCgUCv5yUSCSUSieTteDye6lMCAHwo5TcD7N27V5cuXdITTzzR53mRSEShUCh5hMPhVJ8SAOBDKYdm27ZtKi0tVV5eXp/nVVVVKRaLJY9oNJrqUwIAfCilb519+umnOnTokN58881+zw0GgwoGg6k8DQAgDaR0RVNbW6ucnBwtW7ZssPcAANKM69B0d3ertrZWZWVlyshI+b0EAIBhwnVoDh06pLa2Nq1Zs8ZiDwAgzbi+JCkpKZHjOBZbAABpiN91BgAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAExd94/I5LNsvHHlyhWvJ6Sko6PD6wkp++9//+v1BOC66O/P9YBznf/kP3PmjMLh8PV8SgCAoWg0qkmTJvX6/1/30HR3d+vzzz9XZmamAoHAoP694/G4wuGwotGosrKyBvXvbcmvuyX/bvfrbsm/2/26W/LvduvdjuOoo6NDeXl5GjGi91dirvu3zkaMGNFn+QZDVlaWr74YvuTX3ZJ/t/t1t+Tf7X7dLfl3u+XuUCjU7zm8GQAAYIrQAABMpVVogsGgXnrpJQWDQa+nuOLX3ZJ/t/t1t+Tf7X7dLfl3+1DZfd3fDAAAGF7S6ooGADD0EBoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGDqf64lQwQHsEU+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digit.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fff9cdf-3afd-4477-adc1-618be93ef5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e791cb90-11f7-479c-a934-8b8dd2de94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd0d498d-33a2-4688-8067-309929af849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(estimator= dc, n_estimators= 10)\n",
    "classifiers = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "617ed252-8c7d-4b20-87cf-776cc0fde05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c960deee-bfab-4bf3-8d5b-c92990f0d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9277777777777778\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42ae35a9-b5f5-41a9-a9b4-6b50cc97f7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of  1 is 0.8388888888888889\n",
      "accuracy score of  2 is 0.8222222222222222\n",
      "accuracy score of  3 is 0.8083333333333333\n",
      "accuracy score of  4 is 0.8111111111111111\n",
      "accuracy score of  5 is 0.8083333333333333\n",
      "accuracy score of  6 is 0.8305555555555556\n",
      "accuracy score of  7 is 0.8222222222222222\n",
      "accuracy score of  8 is 0.85\n",
      "accuracy score of  9 is 0.8111111111111111\n",
      "accuracy score of  10 is 0.825\n"
     ]
    }
   ],
   "source": [
    "for i,clf in enumerate(classifiers):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"accuracy score of \",i+1, \"is\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "deee7d21-2a81-4957-b615-3f2d077323bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1fbbd3c1-9934-415c-882e-dd711494a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "0 ---> [6]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "1 ---> [9]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "2 ---> [3]\n",
      "3 ---> [7]\n",
      "3 ---> [9]\n",
      "3 ---> [8]\n",
      "3 ---> [8]\n",
      "3 ---> [7]\n",
      "3 ---> [7]\n",
      "3 ---> [9]\n",
      "3 ---> [7]\n",
      "3 ---> [7]\n",
      "3 ---> [7]\n",
      "4 ---> [2]\n",
      "4 ---> [2]\n",
      "4 ---> [2]\n",
      "4 ---> [2]\n",
      "4 ---> [2]\n",
      "4 ---> [6]\n",
      "4 ---> [2]\n",
      "4 ---> [2]\n",
      "4 ---> [2]\n",
      "4 ---> [2]\n",
      "5 ---> [1]\n",
      "5 ---> [1]\n",
      "5 ---> [2]\n",
      "5 ---> [1]\n",
      "5 ---> [1]\n",
      "5 ---> [1]\n",
      "5 ---> [1]\n",
      "5 ---> [2]\n",
      "5 ---> [1]\n",
      "5 ---> [1]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "6 ---> [5]\n",
      "7 ---> [3]\n",
      "7 ---> [3]\n",
      "7 ---> [3]\n",
      "7 ---> [3]\n",
      "7 ---> [3]\n",
      "7 ---> [1]\n",
      "7 ---> [2]\n",
      "7 ---> [3]\n",
      "7 ---> [9]\n",
      "7 ---> [3]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "8 ---> [5]\n",
      "9 ---> [2]\n",
      "9 ---> [7]\n",
      "9 ---> [7]\n",
      "9 ---> [3]\n",
      "9 ---> [3]\n",
      "9 ---> [7]\n",
      "9 ---> [2]\n",
      "9 ---> [2]\n",
      "9 ---> [3]\n",
      "9 ---> [3]\n",
      "10 ---> [2]\n",
      "10 ---> [1]\n",
      "10 ---> [2]\n",
      "10 ---> [2]\n",
      "10 ---> [2]\n",
      "10 ---> [2]\n",
      "10 ---> [2]\n",
      "10 ---> [2]\n",
      "10 ---> [2]\n",
      "10 ---> [2]\n",
      "11 ---> [4]\n",
      "11 ---> [4]\n",
      "11 ---> [4]\n",
      "11 ---> [4]\n",
      "11 ---> [7]\n",
      "11 ---> [9]\n",
      "11 ---> [1]\n",
      "11 ---> [1]\n",
      "11 ---> [9]\n",
      "11 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "12 ---> [4]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "13 ---> [0]\n",
      "14 ---> [4]\n",
      "14 ---> [5]\n",
      "14 ---> [4]\n",
      "14 ---> [4]\n",
      "14 ---> [4]\n",
      "14 ---> [4]\n",
      "14 ---> [4]\n",
      "14 ---> [4]\n",
      "14 ---> [4]\n",
      "14 ---> [4]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "15 ---> [2]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "16 ---> [3]\n",
      "17 ---> [7]\n",
      "17 ---> [7]\n",
      "17 ---> [7]\n",
      "17 ---> [7]\n",
      "17 ---> [3]\n",
      "17 ---> [7]\n",
      "17 ---> [7]\n",
      "17 ---> [7]\n",
      "17 ---> [7]\n",
      "17 ---> [7]\n",
      "18 ---> [8]\n",
      "18 ---> [8]\n",
      "18 ---> [8]\n",
      "18 ---> [8]\n",
      "18 ---> [2]\n",
      "18 ---> [8]\n",
      "18 ---> [8]\n",
      "18 ---> [8]\n",
      "18 ---> [8]\n",
      "18 ---> [8]\n",
      "19 ---> [4]\n",
      "19 ---> [8]\n",
      "19 ---> [8]\n",
      "19 ---> [4]\n",
      "19 ---> [8]\n",
      "19 ---> [8]\n",
      "19 ---> [9]\n",
      "19 ---> [8]\n",
      "19 ---> [8]\n",
      "19 ---> [8]\n"
     ]
    }
   ],
   "source": [
    "#to check how each individual classfier predicted for a single given sample\n",
    "for j in range(20):\n",
    "    for i,clf in enumerate(classifiers):\n",
    "        print(j, \"--->\", clf.predict(X_test[j].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5fef062-d3aa-4c09-9372-6480f20bec32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check the overall prediction for that single given sample.\n",
    "model.predict(X_test[6].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b506367-e676-45e7-aebb-16201c0743ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'estimator__ccp_alpha': 0.0,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__criterion': 'gini',\n",
       " 'estimator__max_depth': None,\n",
       " 'estimator__max_features': None,\n",
       " 'estimator__max_leaf_nodes': None,\n",
       " 'estimator__min_impurity_decrease': 0.0,\n",
       " 'estimator__min_samples_leaf': 1,\n",
       " 'estimator__min_samples_split': 2,\n",
       " 'estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__monotonic_cst': None,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__splitter': 'best',\n",
       " 'estimator': DecisionTreeClassifier(),\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "424e9b68-ea03-4af2-8cff-7e12e7bed95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00151391 0.00838358 0.02654477 0.00684634 0.0374086\n",
      " 0.         0.         0.         0.003138   0.00870551 0.00144456\n",
      " 0.00150352 0.00077387 0.00148821 0.         0.         0.00928873\n",
      " 0.01835064 0.00428867 0.06552337 0.08144182 0.00206365 0.\n",
      " 0.         0.02501793 0.04030556 0.0621406  0.0444963  0.04924984\n",
      " 0.00660368 0.         0.         0.06337059 0.         0.00311267\n",
      " 0.09295441 0.0172584  0.01497145 0.         0.         0.00621675\n",
      " 0.09726513 0.04908011 0.01729887 0.         0.0101654  0.\n",
      " 0.         0.         0.00407102 0.00153226 0.00127258 0.01215183\n",
      " 0.00103183 0.         0.         0.         0.01128036 0.\n",
      " 0.05898867 0.03145603 0.         0.        ]\n",
      "[0.         0.         0.00116126 0.00441462 0.00116126 0.02936\n",
      " 0.00292325 0.         0.         0.00147796 0.00412891 0.00132715\n",
      " 0.00154834 0.01291715 0.0013548  0.         0.         0.00154834\n",
      " 0.00152923 0.01769749 0.05639826 0.07105685 0.         0.\n",
      " 0.         0.         0.07537786 0.02075505 0.05175725 0.02718492\n",
      " 0.01072078 0.         0.         0.05922959 0.01283077 0.00103223\n",
      " 0.08884929 0.00502399 0.03417937 0.         0.         0.00152823\n",
      " 0.07794767 0.10815783 0.00302133 0.00228041 0.00508174 0.\n",
      " 0.         0.00277072 0.0194857  0.         0.00473733 0.00309668\n",
      " 0.02838918 0.00586435 0.         0.0065965  0.01884138 0.01956781\n",
      " 0.06224841 0.01160555 0.00650777 0.01532546]\n",
      "[0.         0.         0.         0.00386785 0.00693877 0.03131294\n",
      " 0.         0.         0.         0.         0.02446976 0.\n",
      " 0.00977519 0.         0.         0.00103143 0.00299038 0.01583048\n",
      " 0.01433399 0.02133961 0.0404852  0.06254134 0.00077357 0.\n",
      " 0.00152936 0.00742812 0.07069506 0.01945845 0.0511093  0.014794\n",
      " 0.00845986 0.         0.         0.05517309 0.0288005  0.00282111\n",
      " 0.07426148 0.02744344 0.02166123 0.         0.         0.00152588\n",
      " 0.06464839 0.09252584 0.00551904 0.02063813 0.00835478 0.\n",
      " 0.         0.01086614 0.00103143 0.00920563 0.0121592  0.01283782\n",
      " 0.03905196 0.00153308 0.         0.00594022 0.00438172 0.00123771\n",
      " 0.06368303 0.0180114  0.00601129 0.00151181]\n",
      "[0.         0.0014452  0.01259039 0.00101136 0.0112811  0.04310209\n",
      " 0.         0.         0.         0.01562441 0.03417814 0.\n",
      " 0.00823216 0.02295895 0.         0.         0.         0.00270975\n",
      " 0.01454981 0.02356261 0.06635203 0.06890969 0.         0.\n",
      " 0.         0.00129036 0.07740698 0.06208505 0.05082105 0.00812097\n",
      " 0.00486232 0.         0.         0.06193155 0.01233282 0.0044455\n",
      " 0.07668769 0.01546136 0.00895463 0.         0.         0.02502144\n",
      " 0.06322638 0.06686085 0.00321417 0.         0.00922579 0.\n",
      " 0.         0.         0.00609318 0.00800066 0.00759995 0.00116132\n",
      " 0.00103229 0.         0.         0.         0.         0.01961084\n",
      " 0.06175476 0.01176522 0.         0.00452516]\n",
      "[0.         0.         0.00364034 0.00103272 0.         0.02012163\n",
      " 0.00799945 0.         0.         0.01228552 0.02015411 0.00314306\n",
      " 0.00981884 0.00702992 0.         0.         0.         0.00816021\n",
      " 0.01793489 0.06487439 0.01369247 0.1112443  0.         0.\n",
      " 0.         0.005484   0.07617346 0.05710721 0.00283998 0.01738647\n",
      " 0.00174271 0.         0.         0.01809925 0.05204152 0.00123926\n",
      " 0.07117639 0.00792735 0.02270729 0.         0.         0.00116181\n",
      " 0.05473214 0.0835957  0.00722752 0.00343673 0.06131158 0.\n",
      " 0.         0.00116181 0.01119025 0.00641206 0.02208158 0.00634944\n",
      " 0.00077454 0.         0.         0.00268272 0.01149083 0.00230858\n",
      " 0.06940051 0.01255632 0.00706914 0.        ]\n",
      "[0.         0.00153389 0.         0.02526018 0.00518586 0.03975852\n",
      " 0.         0.         0.         0.         0.05770621 0.00347618\n",
      " 0.00691789 0.00997754 0.006001   0.         0.         0.00230647\n",
      " 0.01179275 0.0041408  0.05661412 0.06241151 0.00294382 0.\n",
      " 0.         0.00386384 0.06132162 0.06978874 0.00639471 0.06568332\n",
      " 0.01481909 0.         0.         0.02730714 0.06479492 0.0014756\n",
      " 0.08010527 0.00656766 0.00910977 0.         0.         0.00185926\n",
      " 0.06405578 0.05483756 0.         0.00719822 0.00529866 0.\n",
      " 0.         0.00380362 0.01148515 0.00307988 0.00206584 0.00103292\n",
      " 0.02824976 0.         0.         0.00206584 0.00912533 0.00206584\n",
      " 0.06539911 0.0311188  0.         0.        ]\n",
      "[0.         0.         0.00103237 0.01776783 0.00711748 0.01071196\n",
      " 0.0067758  0.         0.         0.00421311 0.01221398 0.\n",
      " 0.01837263 0.00448614 0.00215691 0.         0.         0.00180664\n",
      " 0.01538466 0.04363549 0.02212962 0.08509824 0.00415594 0.00883158\n",
      " 0.         0.00206474 0.07746974 0.06451273 0.05984119 0.00997432\n",
      " 0.00293249 0.         0.         0.00077428 0.08416297 0.00620594\n",
      " 0.07835156 0.00714933 0.02688442 0.         0.         0.01025019\n",
      " 0.01492295 0.0823087  0.         0.         0.00679966 0.\n",
      " 0.         0.01078328 0.01811638 0.00608452 0.         0.01518277\n",
      " 0.06049282 0.         0.         0.         0.00326302 0.00049497\n",
      " 0.06644458 0.01710453 0.00153757 0.        ]\n",
      "[0.         0.         0.00501469 0.00872574 0.00265469 0.06030943\n",
      " 0.         0.         0.         0.00077428 0.02855191 0.00812495\n",
      " 0.00473652 0.00077428 0.         0.00153077 0.         0.0030403\n",
      " 0.01376922 0.01123942 0.04573855 0.08192274 0.         0.00290049\n",
      " 0.         0.02696254 0.02639308 0.04544932 0.09423903 0.0562521\n",
      " 0.         0.         0.         0.00307728 0.06247446 0.00548635\n",
      " 0.01603354 0.01995325 0.00585363 0.         0.         0.\n",
      " 0.09154865 0.06776831 0.02194282 0.00103238 0.00444153 0.\n",
      " 0.         0.         0.02105806 0.00513239 0.00729883 0.01001753\n",
      " 0.         0.         0.         0.         0.03057268 0.00149695\n",
      " 0.05741728 0.02206434 0.0117562  0.00446949]\n",
      "[0.         0.         0.01398053 0.01035464 0.00462522 0.01540576\n",
      " 0.00583813 0.         0.         0.01805837 0.06116635 0.00129183\n",
      " 0.00479041 0.00407185 0.01614689 0.0015502  0.         0.\n",
      " 0.00804667 0.02267203 0.01880089 0.08340928 0.0015502  0.\n",
      " 0.         0.00199311 0.06894231 0.05258745 0.09192771 0.00895259\n",
      " 0.00984617 0.         0.         0.07416633 0.03716371 0.00558588\n",
      " 0.02266808 0.01487563 0.0706366  0.         0.         0.\n",
      " 0.00553642 0.07208851 0.00898497 0.00810193 0.07070423 0.\n",
      " 0.         0.         0.00591995 0.         0.01009512 0.02182937\n",
      " 0.00764803 0.         0.         0.         0.00402198 0.00373708\n",
      " 0.01540471 0.0137894  0.00103346 0.        ]\n",
      "[0.         0.         0.0181682  0.01183591 0.00968768 0.04354546\n",
      " 0.00153843 0.         0.         0.01446741 0.02264815 0.00320181\n",
      " 0.01505604 0.02555378 0.         0.         0.         0.00077463\n",
      " 0.00295768 0.01266355 0.03919433 0.09422394 0.         0.\n",
      " 0.         0.         0.04647264 0.0561712  0.         0.05381327\n",
      " 0.00412584 0.         0.         0.06391179 0.031188   0.00206568\n",
      " 0.08001211 0.         0.         0.         0.         0.\n",
      " 0.07679983 0.0586554  0.0209273  0.01317145 0.         0.\n",
      " 0.         0.         0.00593528 0.         0.00792286 0.00142016\n",
      " 0.0546759  0.         0.         0.00656052 0.         0.00451868\n",
      " 0.06363687 0.02103796 0.00153492 0.00992535]\n"
     ]
    }
   ],
   "source": [
    "for i,clf in enumerate(classifiers):\n",
    "    print(clf.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
